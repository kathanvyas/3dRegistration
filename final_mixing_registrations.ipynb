{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import glob\n",
    "import copy\n",
    "import math\n",
    "\n",
    "voxel_size = 0.035\n",
    "max_correspondence_dist_coarse = voxel_size * 15\n",
    "max_correspondence_dist_fine = voxel_size * 1.5\n",
    "radius_normal = voxel_size * 2\n",
    "radius_feature = voxel_size * 5\n",
    "\n",
    "def preprocess_point_cloud(pcd, voxel_size):\n",
    "    radius_normal = voxel_size * 2\n",
    "    #print(\":: Estimate normal with search radius %.3f.\" % radius_normal)\n",
    "    o3d.geometry.estimate_normals(pcd,o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))\n",
    "    radius_feature = voxel_size * 5\n",
    "    #print(\":: Compute FPFH feature with search radius %.3f.\" % radius_feature)\n",
    "    pcd_fpfh = o3d.registration.compute_fpfh_feature(pcd,o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=300))\n",
    "    return pcd_fpfh\n",
    "\n",
    "\n",
    "def load_point_clouds(directory ,voxel_size ,n,g):\n",
    "    pcds = []\n",
    "    fpfh = []\n",
    "    for i in range(n):\n",
    "        pcd = o3d.io.read_point_cloud(directory + \"%d.ply\" % i)\n",
    "        #pcd_down = o3d.geometry.voxel_down_sample(pcd, voxel_size=voxel_size)\n",
    "        pcd_down = pcd\n",
    "        ss = np.asarray(pcd_down.points)\n",
    "        ss = ss - np.mean(ss)\n",
    "        pcd_down.points = o3d.utility.Vector3dVector(ss)\n",
    "\n",
    "        pcd_fpfh = preprocess_point_cloud(pcd_down, voxel_size)\n",
    "        fpfh.append(pcd_fpfh)\n",
    "        pcds.append(pcd_down)\n",
    "    return pcds, fpfh\n",
    "\n",
    "def draw_registration_result(source, target, transformation):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.paint_uniform_color([0, 0.706, 0])\n",
    "    target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp])\n",
    "\n",
    "def execute_global_registration(source, target, source_fpfh, target_fpfh, voxel_size):\n",
    "    #voxel_size = 0.035\n",
    "    distance_threshold = voxel_size * 1.5\n",
    "    print(\":: RANSAC registration on downsampled point clouds.\")\n",
    "    print(\"   Since the downsampling voxel size is %.3f,\" % voxel_size)\n",
    "    print(\"   we use a liberal distance threshold %.3f.\" % distance_threshold)\n",
    "    result = o3d.registration.registration_ransac_based_on_feature_matching(\n",
    "        source, target, source_fpfh, target_fpfh, distance_threshold,\n",
    "        o3d.registration.TransformationEstimationPointToPoint(False), 30, \n",
    "        [o3d.registration.CorrespondenceCheckerBasedOnEdgeLength(0.5),\n",
    "         o3d.registration.CorrespondenceCheckerBasedOnDistance(distance_threshold)],\n",
    "        o3d.registration.RANSACConvergenceCriteria(4000000, 500))\n",
    "    print(result)    \n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def pairwise_registration(source, target, source_fpfh, target_fpfh, voxel_size):\n",
    "    result_ransac = execute_global_registration(source, target,source_fpfh, target_fpfh, voxel_size)\n",
    "    icp_fine = o3d.registration.registration_icp(source, target, max_correspondence_dist_fine,\n",
    "                                                 result_ransac.transformation,\n",
    "                                                 o3d.registration.TransformationEstimationPointToPlane())\n",
    "    transformation_icp = icp_fine.transformation\n",
    "    information_icp = o3d.registration.get_information_matrix_from_point_clouds(source, target, \n",
    "                                                                                max_correspondence_dist_fine,\n",
    "                                                                                icp_fine.transformation)\n",
    "    print(icp_fine)\n",
    "    return transformation_icp, information_icp\n",
    "\n",
    "\n",
    "def main_registration(pcds,fpfh, max_correspondence_dist_coarse,max_correspondence_dist_fine, voxel_size):\n",
    "    pose_graph = o3d.registration.PoseGraph()\n",
    "    odometry = np.identity(4)\n",
    "    pose_graph.nodes.append(o3d.registration.PoseGraphNode(odometry))\n",
    "    n_pcds = len(pcds)\n",
    "    for source_id in range(n_pcds):\n",
    "            target_id = (source_id + 1) % n_pcds\n",
    "            print(\"performing transformation for:\")\n",
    "            print(source_id)\n",
    "            print(target_id)\n",
    "            transformation_icp, information_icp = pairwise_registration(pcds[source_id], pcds[target_id], \n",
    "                                                                        fpfh[source_id], fpfh[target_id],\n",
    "                                                                        voxel_size)\n",
    "            draw_registration_result(pcds[source_id], pcds[target_id], transformation_icp)\n",
    "            print(\"Build o3d.registration.PoseGraph\")\n",
    "            if target_id == source_id + 1:  # odometry case\n",
    "                odometry = np.dot(transformation_icp, odometry)\n",
    "                pose_graph.nodes.append(o3d.registration.PoseGraphNode(np.linalg.inv(odometry)))\n",
    "                pose_graph.edges.append(o3d.registration.PoseGraphEdge(source_id,target_id,transformation_icp,\n",
    "                                                                       information_icp,uncertain=False))\n",
    "    \n",
    "            #else:  # loop closure case\n",
    "                #pose_graph.edges.append(o3d.registration.PoseGraphEdge(source_id,target_id,transformation_icp,\n",
    "                                                                       #information_icp,uncertain=True))\n",
    "    return pose_graph\n",
    "\n",
    "def final_fun(dirtry, g):\n",
    "    #Directory of Point-cloud goes here\n",
    "    directory = dirtry\n",
    "    n = len(glob.glob1(directory,\"*.ply\"))\n",
    "    o3d.utility.set_verbosity_level(o3d.utility.VerbosityLevel.Debug)\n",
    "    \n",
    "    pcds_down, pcd_fpfh = load_point_clouds(directory,voxel_size,n,g)\n",
    "    o3d.visualization.draw_geometries(pcds_down)\n",
    "    n_pcds = len(pcds_down)\n",
    "    \n",
    "    #Implementing Full Registration\n",
    "    print(\"Full registration ...\")\n",
    "    pose_graph = main_registration(pcds_down, pcd_fpfh, max_correspondence_dist_coarse,max_correspondence_dist_fine, voxel_size)\n",
    "\n",
    "    #Implementing Global Optimization\n",
    "    print(\"Optimizing PoseGraph ...\")\n",
    "    option = o3d.registration.GlobalOptimizationOption(max_correspondence_distance=max_correspondence_dist_fine,\n",
    "                                                       edge_prune_threshold=0.5,reference_node=0)\n",
    "    o3d.registration.global_optimization(\n",
    "        pose_graph, o3d.registration.GlobalOptimizationLevenbergMarquardt(),\n",
    "        o3d.registration.GlobalOptimizationConvergenceCriteria(), option)\n",
    "\n",
    "    print(\"Transform points and display\")\n",
    "    pcd_combined = o3d.geometry.PointCloud()\n",
    "    for point_id in range(len(pcds_down)):\n",
    "        print(point_id)\n",
    "        print(pose_graph.nodes[point_id].pose)\n",
    "        pcds_down[point_id].transform(pose_graph.nodes[point_id].pose)\n",
    "        pcd_combined += pcds_down[point_id]\n",
    "    o3d.visualization.draw_geometries(pcds_down)\n",
    "    #pcd_combined_down = o3d.geometry.voxel_down_sample(pcd_combined,voxel_size=voxel_size)\n",
    "    o3d.io.write_point_cloud(dirtry + \"multiway_registration.ply\", pcd_combined)\n",
    "    #o3d.visualization.draw_geometries([pcd_combined])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Full registration ...\nperforming transformation for:\n0\n1\n:: RANSAC registration on downsampled point clouds.\n   Since the downsampling voxel size is 0.035,\n   we use a liberal distance threshold 0.053.\nregistration::RegistrationResult with fitness = 0.000000, inlier_rmse = 0.000000, and correspondence_set size of 0\nAccess transformation to get result.\nregistration::RegistrationResult with fitness = 0.952286, inlier_rmse = 0.008380, and correspondence_set size of 13911\nAccess transformation to get result.\nBuild o3d.registration.PoseGraph\nperforming transformation for:\n1\n2\n:: RANSAC registration on downsampled point clouds.\n   Since the downsampling voxel size is 0.035,\n   we use a liberal distance threshold 0.053.\nregistration::RegistrationResult with fitness = 0.000000, inlier_rmse = 0.000000, and correspondence_set size of 0\nAccess transformation to get result.\nregistration::RegistrationResult with fitness = 0.963554, inlier_rmse = 0.010696, and correspondence_set size of 14911\nAccess transformation to get result.\nBuild o3d.registration.PoseGraph\nperforming transformation for:\n2\n3\n:: RANSAC registration on downsampled point clouds.\n   Since the downsampling voxel size is 0.035,\n   we use a liberal distance threshold 0.053.\nregistration::RegistrationResult with fitness = 0.000000, inlier_rmse = 0.000000, and correspondence_set size of 0\nAccess transformation to get result.\nregistration::RegistrationResult with fitness = 0.993074, inlier_rmse = 0.009296, and correspondence_set size of 14911\nAccess transformation to get result.\nBuild o3d.registration.PoseGraph\nperforming transformation for:\n3\n4\n:: RANSAC registration on downsampled point clouds.\n   Since the downsampling voxel size is 0.035,\n   we use a liberal distance threshold 0.053.\nregistration::RegistrationResult with fitness = 0.000000, inlier_rmse = 0.000000, and correspondence_set size of 0\nAccess transformation to get result.\nregistration::RegistrationResult with fitness = 0.971624, inlier_rmse = 0.011545, and correspondence_set size of 14039\nAccess transformation to get result.\nBuild o3d.registration.PoseGraph\nperforming transformation for:\n4\n5\n:: RANSAC registration on downsampled point clouds.\n   Since the downsampling voxel size is 0.035,\n   we use a liberal distance threshold 0.053.\nregistration::RegistrationResult with fitness = 0.000000, inlier_rmse = 0.000000, and correspondence_set size of 0\nAccess transformation to get result.\nregistration::RegistrationResult with fitness = 0.755102, inlier_rmse = 0.014892, and correspondence_set size of 9435\nAccess transformation to get result.\nBuild o3d.registration.PoseGraph\nperforming transformation for:\n5\n6\n:: RANSAC registration on downsampled point clouds.\n   Since the downsampling voxel size is 0.035,\n   we use a liberal distance threshold 0.053.\nregistration::RegistrationResult with fitness = 0.000000, inlier_rmse = 0.000000, and correspondence_set size of 0\nAccess transformation to get result.\nregistration::RegistrationResult with fitness = 0.993943, inlier_rmse = 0.008412, and correspondence_set size of 9354\nAccess transformation to get result.\nBuild o3d.registration.PoseGraph\nperforming transformation for:\n6\n7\n:: RANSAC registration on downsampled point clouds.\n   Since the downsampling voxel size is 0.035,\n   we use a liberal distance threshold 0.053.\nregistration::RegistrationResult with fitness = 0.000000, inlier_rmse = 0.000000, and correspondence_set size of 0\nAccess transformation to get result.\nregistration::RegistrationResult with fitness = 0.989754, inlier_rmse = 0.008765, and correspondence_set size of 12171\nAccess transformation to get result.\nBuild o3d.registration.PoseGraph\nperforming transformation for:\n7\n8\n:: RANSAC registration on downsampled point clouds.\n   Since the downsampling voxel size is 0.035,\n   we use a liberal distance threshold 0.053.\nregistration::RegistrationResult with fitness = 0.000000, inlier_rmse = 0.000000, and correspondence_set size of 0\nAccess transformation to get result.\nregistration::RegistrationResult with fitness = 0.999822, inlier_rmse = 0.007638, and correspondence_set size of 16840\nAccess transformation to get result.\nBuild o3d.registration.PoseGraph\nperforming transformation for:\n8\n9\n:: RANSAC registration on downsampled point clouds.\n   Since the downsampling voxel size is 0.035,\n   we use a liberal distance threshold 0.053.\nregistration::RegistrationResult with fitness = 0.000000, inlier_rmse = 0.000000, and correspondence_set size of 0\nAccess transformation to get result.\nregistration::RegistrationResult with fitness = 0.994984, inlier_rmse = 0.007107, and correspondence_set size of 19637\nAccess transformation to get result.\nBuild o3d.registration.PoseGraph\nperforming transformation for:\n9\n10\n:: RANSAC registration on downsampled point clouds.\n   Since the downsampling voxel size is 0.035,\n   we use a liberal distance threshold 0.053.\nregistration::RegistrationResult with fitness = 0.000000, inlier_rmse = 0.000000, and correspondence_set size of 0\nAccess transformation to get result.\nregistration::RegistrationResult with fitness = 0.991853, inlier_rmse = 0.008171, and correspondence_set size of 18992\nAccess transformation to get result.\nBuild o3d.registration.PoseGraph\nperforming transformation for:\n10\n11\n:: RANSAC registration on downsampled point clouds.\n   Since the downsampling voxel size is 0.035,\n   we use a liberal distance threshold 0.053.\nregistration::RegistrationResult with fitness = 0.000000, inlier_rmse = 0.000000, and correspondence_set size of 0\nAccess transformation to get result.\nregistration::RegistrationResult with fitness = 0.892875, inlier_rmse = 0.012906, and correspondence_set size of 14261\nAccess transformation to get result.\nBuild o3d.registration.PoseGraph\nperforming transformation for:\n11\n12\n:: RANSAC registration on downsampled point clouds.\n   Since the downsampling voxel size is 0.035,\n   we use a liberal distance threshold 0.053.\nregistration::RegistrationResult with fitness = 0.000000, inlier_rmse = 0.000000, and correspondence_set size of 0\nAccess transformation to get result.\nregistration::RegistrationResult with fitness = 0.858203, inlier_rmse = 0.009677, and correspondence_set size of 9139\nAccess transformation to get result.\nBuild o3d.registration.PoseGraph\nperforming transformation for:\n12\n13\n:: RANSAC registration on downsampled point clouds.\n   Since the downsampling voxel size is 0.035,\n   we use a liberal distance threshold 0.053.\nregistration::RegistrationResult with fitness = 0.000000, inlier_rmse = 0.000000, and correspondence_set size of 0\nAccess transformation to get result.\nregistration::RegistrationResult with fitness = 0.981850, inlier_rmse = 0.008750, and correspondence_set size of 10170\nAccess transformation to get result.\nBuild o3d.registration.PoseGraph\nperforming transformation for:\n13\n14\n:: RANSAC registration on downsampled point clouds.\n   Since the downsampling voxel size is 0.035,\n   we use a liberal distance threshold 0.053.\nregistration::RegistrationResult with fitness = 0.000000, inlier_rmse = 0.000000, and correspondence_set size of 0\nAccess transformation to get result.\nregistration::RegistrationResult with fitness = 0.999528, inlier_rmse = 0.005444, and correspondence_set size of 12703\nAccess transformation to get result.\nBuild o3d.registration.PoseGraph\nperforming transformation for:\n14\n15\n:: RANSAC registration on downsampled point clouds.\n   Since the downsampling voxel size is 0.035,\n   we use a liberal distance threshold 0.053.\n"
    }
   ],
   "source": [
    "import easydict\n",
    "if __name__ == \"__main__\":\n",
    "    n = input(\"How many Pcds do you have?\")\n",
    "    ang = input(\"Do you know their Angles? Y Or N\")\n",
    "    args = easydict.EasyDict({\n",
    "                           \"dir\": \"C:/Users/Kathan/Desktop/ACLAB/3D_Registeration/DATA/manne_top/iteration2/raw_hands2/\",\n",
    "                           \"n\": int(n),\n",
    "                           \"angle\" : ang \n",
    "                         })\n",
    "    g = []    \n",
    "    if args.angle == \"yes\" or args.angle == \"y\":\n",
    "        g = []\n",
    "        for i in range(1,args.n):\n",
    "            print(\"Enter angle for pointcloud\", i)\n",
    "            h = input()  \n",
    "            g.append(h)\n",
    "    final_fun(args.dir, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}